{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "phoneticDict = {}\n",
    "ambiguousTerms = {}\n",
    "\n",
    "with open('cmudict') as f:\n",
    "    for line in f:\n",
    "        if line.startswith(';;;') or line.startswith('@@'):\n",
    "            continue\n",
    "        \n",
    "        word, phonemes = line.strip().split(maxsplit=1)\n",
    "        if \"#@@\" in phonemes:\n",
    "            phonemes = phonemes.split('#@@')[0].strip()\n",
    "\n",
    "        if '(' not in word:\n",
    "            phoneticDict[word] = phonemes\n",
    "            continue\n",
    "\n",
    "        lemma, PoS = word.split(\"(\")\n",
    "        PoS = PoS.rstrip(\")\")\n",
    "\n",
    "        if lemma in phoneticDict:\n",
    "            if PoS in ['2', '3']:\n",
    "                if isinstance(phoneticDict[lemma], list):\n",
    "                    phoneticDict[lemma].append(phonemes)\n",
    "                else:\n",
    "                    phoneticDict[lemma] = [phoneticDict[lemma], phonemes]\n",
    "            else:\n",
    "                phoneticDict[lemma][PoS] = phonemes\n",
    "        else:\n",
    "            phoneticDict[lemma] = {PoS:phonemes}\n",
    "\n",
    "with open('phoneticDict.json', 'w') as f:\n",
    "    json.dump(phoneticDict, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "phoneticDict = {}\n",
    "ambiguousTerms = {}\n",
    "\n",
    "with open('cmudict') as f:\n",
    "    for line in f:\n",
    "        if line.startswith(';;;') or line.startswith('@@'):\n",
    "            continue\n",
    "        \n",
    "        word, phonemes = line.strip().split(maxsplit=1)\n",
    "        if \"#@@\" in phonemes:\n",
    "            phonemes = phonemes.split('#@@')[0].strip()\n",
    "\n",
    "        if '(' not in word:\n",
    "            phoneticDict[word] = phonemes\n",
    "            continue\n",
    "\n",
    "        lemma, PoS = word.split(\"(\")\n",
    "        PoS = PoS.rstrip(\")\")\n",
    "\n",
    "        if lemma in phoneticDict:\n",
    "            if PoS in ['2', '3']:\n",
    "                if isinstance(phoneticDict[lemma], list):\n",
    "                    phoneticDict[lemma].append(phonemes)\n",
    "                else:\n",
    "                    phoneticDict[lemma] = [phoneticDict[lemma], phonemes]\n",
    "            else:\n",
    "                phoneticDict[lemma][PoS] = phonemes\n",
    "        else:\n",
    "            phoneticDict[lemma] = {PoS:phonemes}\n",
    "\n",
    "with open('phoneticDict.json', 'w') as f:\n",
    "    json.dump(phoneticDict, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arpabet_to_ipa = {\n",
    "    \"AA\": \"ɑ~ɒ\",\n",
    "    \"AE\": \"æ\",\n",
    "    \"AH\": \"ʌ\",\n",
    "    \"AO\": \"ɔ\",\n",
    "    \"AW\": \"aʊ\",\n",
    "    \"AX\": \"ə\",\n",
    "    \"AXR\": \"ɚ\",\n",
    "    \"AY\": \"aɪ\",\n",
    "    \"EH\": \"ɛ\",\n",
    "    \"ER\": \"ɝ\",\n",
    "    \"EY\": \"eɪ\",\n",
    "    \"IH\": \"ɪ\",\n",
    "    \"IX\": \"ɨ\",\n",
    "    \"IY\": \"i\",\n",
    "    \"OW\": \"oʊ\",\n",
    "    \"OY\": \"ɔɪ\",\n",
    "    \"UH\": \"ʊ\",\n",
    "    \"UW\": \"u\",\n",
    "    \"UX\": \"ʉ\",\n",
    "    \"B\": \"b\",\n",
    "    \"CH\": \"tʃ\",\n",
    "    \"D\": \"d\",\n",
    "    \"DH\": \"ð\",\n",
    "    \"DX\": \"ɾ\",\n",
    "    \"EL\": \"l̩\",\n",
    "    \"EM\": \"m̩\",\n",
    "    \"EN\": \"n̩\",\n",
    "    \"F\": \"f\",\n",
    "    \"G\": \"ɡ\",\n",
    "    \"HH\": \"h\",\n",
    "    \"JH\": \"dʒ\",\n",
    "    \"K\": \"k\",\n",
    "    \"L\": \"l\",\n",
    "    \"M\": \"m\",\n",
    "    \"N\": \"n\",\n",
    "    \"NX\": \"ŋ\",\n",
    "    \"NG\":\"ŋ\",\n",
    "    \"P\": \"p\",\n",
    "    \"Q\": \"ʔ\",\n",
    "    \"R\": \"ɹ\",\n",
    "    \"S\": \"s\",\n",
    "    \"SH\": \"ʃ\",\n",
    "    \"T\": \"t\",\n",
    "    \"TH\": \"θ\",\n",
    "    \"V\": \"v\",\n",
    "    \"W\": \"w\",\n",
    "    \"WH\": \"ʍ\",\n",
    "    \"Y\": \"j\",\n",
    "    \"Z\": \"z\",\n",
    "    \"ZH\": \"ʒ\",\n",
    "    \"P\": \"p\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accent = {0:'',1:\"ˈ\",2:\"ˌ\"}\n",
    "\n",
    "def arpabet_to_ipa_transcription(arpabet_transcription):\n",
    "    ipa_transcription = ''\n",
    "    if isinstance(arpabet_transcription, list):\n",
    "        arpabet_transcription = arpabet_transcription[0]\n",
    "    for phoneme in arpabet_transcription.split():\n",
    "        if phoneme == '#':\n",
    "            break\n",
    "        if phoneme[-1].isdigit():\n",
    "            stress = int(phoneme[-1])\n",
    "            arpabet_phoneme = phoneme[:-1]\n",
    "        else:\n",
    "            stress = 0\n",
    "            arpabet_phoneme = phoneme\n",
    "\n",
    "        ipa_phoneme = arpabet_to_ipa[arpabet_phoneme]\n",
    "        ipa_transcription += accent[stress] + ipa_phoneme\n",
    "\n",
    "    return ipa_transcription.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('static/phoneticDict.json', 'r') as f:\n",
    "    arpabet_dict = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPA_dict = {}\n",
    "\n",
    "for word, transcription in arpabet_dict.items():\n",
    "    if isinstance(transcription, dict):\n",
    "        IPA_dict[word] = {}\n",
    "        for pos, pos_transcription in transcription.items():\n",
    "            ipa_transcription = arpabet_to_ipa_transcription(pos_transcription)\n",
    "            IPA_dict[word][pos] = ipa_transcription\n",
    "    else:\n",
    "        ipa_transcription = arpabet_to_ipa_transcription(transcription)\n",
    "        IPA_dict[word] = ipa_transcription\n",
    "\n",
    "with open('static/IPA_dict.json', 'w') as f:\n",
    "    \n",
    "    json.dump(IPA_dict, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = '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'\n",
    "\n",
    "role = \"Respond in a useful manner for an English student. If any challenging linguistic structure is found in the sentence, address it in your explanation. Be brief, a little friendly, add two examples. Your response should be in Spanish.\"\n",
    "userEg = \"\"\"Word: kitten (Singular)\n",
    "Sentence: Mary was walking home from work when she saw an abandoned kitten on the side of the road.\n",
    "Complements:\n",
    "  an \n",
    "  abandoned \n",
    "  on the side of the road\n",
    "Grammar function: Direct object of 'saw'\"\"\"\n",
    "assintantEg = \"\"\"\"kitten\" es un sustantivo singular que funciona como objeto directo del verbo \"saw\", es decir, la acción es realizada sobre el gatito, Mary vio un gatito. Los complementos que lo acompañan son \"an\" (artículo), \"abandoned\" (adjetivo) y \"on the side of the road\" (complemento preposicional) y especifican que se trata de un gatito en particular, y describen su estado y ubicación.\n",
    "\n",
    "Los verbos \"was walking\" indican la acción de caminar de Mary, mientras que el adverbio de tiempo \"when\" señala el momento en que vio al gatito. El verbo \"saw\" denota la acción que realizó Mary, observar al gatito abandonado. \n",
    "\n",
    "Oraciones similares:\n",
    "\n",
    "\tSarah found an injured kitten in the backyard.\n",
    "\t(Sarah encontró un gatito herido en el patio trasero)\n",
    "\n",
    "\tI think I saw a cute kitten in the living room.\n",
    "\t(Me parece que vi un lindo gatito en la sala de estar)\"\"\"\n",
    "\n",
    "request = \"\"\"Word: work(Singular)\n",
    "Sentence: Mary was walking home from work when she saw an abandoned kitten on the side of the road. \n",
    "Function: Object of a preposition of 'from\"\"\"\n",
    "\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": role},\n",
    "        {\"role\": \"user\", \"content\": userEg},\n",
    "        {\"role\": \"assistant\",\n",
    "            \"content\": assintantEg},\n",
    "        {\"role\": \"user\", \"content\": request}\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = response['choices'][0]['message']['content']\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai\n",
    "\n",
    "openai.api_key = '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'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "promp = \"\"\"role = <Respond in a useful manner for an English student. If any challenging linguistic structure is found in the sentence, address it in your explanation. Be brief, a little friendly, add two examples. Your response should be in Spanish.>\n",
    "\n",
    "user = <Word: kitten (Singular)\n",
    "Sentence: Mary was walking home from work when she saw an abandoned kitten on the side of the road.\n",
    "Complements:\n",
    "  an \n",
    "  abandoned \n",
    "  on the side of the road\n",
    "Grammar function: Direct object of 'saw'>\n",
    "\n",
    "assintant = <kitten\" es un sustantivo singular que funciona como objeto directo del verbo \"saw\", es decir, la acción es realizada sobre el gatito, Mary vio un gatito. Los complementos que lo acompañan son \"an\" (artículo), \"abandoned\" (adjetivo) y \"on the side of the road\" (complemento preposicional) y especifican que se trata de un gatito en particular, y describen su estado y ubicación.\n",
    "\n",
    "Los verbos \"was walking\" indican la acción de caminar de Mary, mientras que el adverbio de tiempo \"when\" señala el momento en que vio al gatito. El verbo \"saw\" denota la acción que realizó Mary, observar al gatito abandonado. \n",
    "\n",
    "Oraciones similares:\n",
    "\n",
    "\tSarah found an injured kitten in the backyard.\n",
    "\t(Sarah encontró un gatito herido en el patio trasero)\n",
    "\n",
    "\tI think I saw a cute kitten in the living room.\n",
    "\t(Me parece que vi un lindo gatito en la sala de estar)>\n",
    "\n",
    "user = <Word: work(Singular)\n",
    "Sentence: Mary was walking home from work when she saw an abandoned kitten on the side of the road. \n",
    "Function: Object of a preposition of 'from>\n",
    "\n",
    "assistant = <[insert]>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=promp, temperature=0.4, max_tokens=427)\n",
    "\n",
    "message = response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n'\n",
      " '\\n'\n",
      " 'Respuesta: \"Work\" es un sustantivo singular que funciona como objeto de la '\n",
      " 'preposición \"from\", es decir, la preposición \"from\" se refiere a la acción '\n",
      " 'de caminar de Mary desde su trabajo. Esta preposición señala el origen de la '\n",
      " 'acción de Mary.\\n'\n",
      " '\\n'\n",
      " 'Oraciones similares:\\n'\n",
      " '\\n'\n",
      " '\\tHe drove to work every day.\\n'\n",
      " '\\t(Él manejaba al trabajo todos los días)\\n'\n",
      " '\\n'\n",
      " '\\tShe was walking home from school.\\n'\n",
      " '\\t(Ella caminaba a casa desde la escuela)')\n",
      "<OpenAIObject text_completion id=cmpl-7FYQX2zDByvAV0R5FBrBBVNOZ7Nel at 0x7f7f8a3f74d0> JSON: {\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \"\\n\\nRespuesta: \\\"Work\\\" es un sustantivo singular que funciona como objeto de la preposici\\u00f3n \\\"from\\\", es decir, la preposici\\u00f3n \\\"from\\\" se refiere a la acci\\u00f3n de caminar de Mary desde su trabajo. Esta preposici\\u00f3n se\\u00f1ala el origen de la acci\\u00f3n de Mary.\\n\\nOraciones similares:\\n\\n\\tHe drove to work every day.\\n\\t(\\u00c9l manejaba al trabajo todos los d\\u00edas)\\n\\n\\tShe was walking home from school.\\n\\t(Ella caminaba a casa desde la escuela)\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1683941613,\n",
      "  \"id\": \"cmpl-7FYQX2zDByvAV0R5FBrBBVNOZ7Nel\",\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 149,\n",
      "    \"prompt_tokens\": 470,\n",
      "    \"total_tokens\": 619\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint as pp\n",
    "\n",
    "pp(message)\n",
    "# print()\n",
    "pp(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "vscode": {
   "interpreter": {
    "hash": "ead1b95f633dc9c51826328e1846203f51a198c6fb5f2884a80417ba131d4e82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
