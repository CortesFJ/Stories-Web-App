{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "db = pd.read_pickle('static/lexicon.pkl')\n",
    "db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('wiki_data_trans.json', 'r') as f:\n",
    "    wiki_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_dict = {}\n",
    "for k in wiki_data:\n",
    "    if 'pronunciation' in wiki_data[k]:\n",
    "        pronunciation = wiki_data[k]['pronunciation']\n",
    "        ph_dict[k]= {\n",
    "        'pronunciation':pronunciation\n",
    "        }\n",
    "\n",
    "ph_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('static/phAids.json', 'r') as f:\n",
    "    aids = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k,v in aids.items():\n",
    "    if k in ph_dict:\n",
    "        ph_dict[k]['aid']=v\n",
    "    else:\n",
    "        ph_dict[k] = {\n",
    "           'aid':v \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ph_dict['make']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k,v in aids.items():\n",
    "    entry = db[db['word'] == k]\n",
    "    for i, row in entry.iterrows():\n",
    "        phonetics = db.at[i,('phonetics')]\n",
    "        if isinstance(phonetics, dict):\n",
    "            phonetics['aid'] = v\n",
    "        else:\n",
    "            phonetics = {'aid': v}\n",
    "        db.at[i,('phonetics')] = phonetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.to_pickle('lexicon.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db[db['word']=='always']['phonetics'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db[db['word']=='determined']['phonetics'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_sound_of(word):\n",
    "\tapiKey = '18daa199-2a7d-4c78-8a0d-732dda4dd277'\n",
    "\turl =f'https://www.dictionaryapi.com/api/v3/references/spanish/json/{word}?key={apiKey}'\n",
    "\n",
    "\tresponse = requests.get(url)\n",
    "\tdata = response.json()\n",
    "\taudioDir = data[0]['hwi']['prs'][0]['sound']['audio']\n",
    "\tsubDir = audioDir[0]\n",
    "\taudio_url = f'https://media.merriam-webster.com/audio/prons/en/us/mp3/{subDir}/{audioDir}.mp3'\n",
    "\taudio_response = requests.get(audio_url)\n",
    "\tprint(audio_response)\n",
    "\twith open(f'{word}.mp3', 'wb') as f:\n",
    "\t\tf.write(audio_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sound_of('word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "elements = ['stories', 'word']\n",
    "data = asyncio.run(fetch_all_data(elements))\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import language_v1\n",
    "\n",
    "client = language_v1.LanguageServiceClient()\n",
    "text = 'this is a text for testing and all I want is it to go well '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = language_v1.Document(\n",
    "    content=text, type=language_v1.Document.Type.PLAIN_TEXT)\n",
    "encoding_type = language_v1.EncodingType.UTF8\n",
    "language = \"en\"\n",
    "\n",
    "\n",
    "response = client.analyze_syntax(\n",
    "    request={\"document\": document,\n",
    "             \"encoding_type\": encoding_type}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__bool__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_methods = [method_name for method_name in dir(response)\n",
    "                  if callable(getattr(response, method_name))]\n",
    "\n",
    "object_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "result_json = response.__class__.to_json(response)\n",
    "result_dict = json.loads(result_json)\n",
    "type(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a text for testing and all I want is it to go well\n"
     ]
    }
   ],
   "source": [
    "for sent in response.sentences:\n",
    "    print(sent.text.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "phoneticDict = {}\n",
    "ambiguousTerms = {}\n",
    "\n",
    "with open('cmudict') as f:\n",
    "    for line in f:\n",
    "        if line.startswith(';;;') or line.startswith('@@'):\n",
    "            continue\n",
    "        \n",
    "        word, phonemes = line.strip().split(maxsplit=1)\n",
    "        if \"#@@\" in phonemes:\n",
    "            phonemes = phonemes.split('#@@')[0].strip()\n",
    "\n",
    "        if '(' not in word:\n",
    "            phoneticDict[word] = phonemes\n",
    "            continue\n",
    "\n",
    "        lemma, PoS = word.split(\"(\")\n",
    "        PoS = PoS.rstrip(\")\")\n",
    "\n",
    "        if lemma in phoneticDict:\n",
    "            if PoS in ['2', '3']:\n",
    "                if isinstance(phoneticDict[lemma], list):\n",
    "                    phoneticDict[lemma].append(phonemes)\n",
    "                else:\n",
    "                    phoneticDict[lemma] = [phoneticDict[lemma], phonemes]\n",
    "            else:\n",
    "                phoneticDict[lemma][PoS] = phonemes\n",
    "        else:\n",
    "            phoneticDict[lemma] = {PoS:phonemes}\n",
    "\n",
    "with open('phoneticDict.json', 'w') as f:\n",
    "    json.dump(phoneticDict, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arpabet_to_ipa = {\n",
    "    \"AA\": \"ɑ~ɒ\",\n",
    "    \"AE\": \"æ\",\n",
    "    \"AH\": \"ʌ\",\n",
    "    \"AO\": \"ɔ\",\n",
    "    \"AW\": \"aʊ\",\n",
    "    \"AX\": \"ə\",\n",
    "    \"AXR\": \"ɚ\",\n",
    "    \"AY\": \"aɪ\",\n",
    "    \"EH\": \"ɛ\",\n",
    "    \"ER\": \"ɝ\",\n",
    "    \"EY\": \"eɪ\",\n",
    "    \"IH\": \"ɪ\",\n",
    "    \"IX\": \"ɨ\",\n",
    "    \"IY\": \"i\",\n",
    "    \"OW\": \"oʊ\",\n",
    "    \"OY\": \"ɔɪ\",\n",
    "    \"UH\": \"ʊ\",\n",
    "    \"UW\": \"u\",\n",
    "    \"UX\": \"ʉ\",\n",
    "    \"B\": \"b\",\n",
    "    \"CH\": \"tʃ\",\n",
    "    \"D\": \"d\",\n",
    "    \"DH\": \"ð\",\n",
    "    \"DX\": \"ɾ\",\n",
    "    \"EL\": \"l̩\",\n",
    "    \"EM\": \"m̩\",\n",
    "    \"EN\": \"n̩\",\n",
    "    \"F\": \"f\",\n",
    "    \"G\": \"ɡ\",\n",
    "    \"HH\": \"h\",\n",
    "    \"JH\": \"dʒ\",\n",
    "    \"K\": \"k\",\n",
    "    \"L\": \"l\",\n",
    "    \"M\": \"m\",\n",
    "    \"N\": \"n\",\n",
    "    \"NX\": \"ŋ\",\n",
    "    \"NG\":\"ŋ\",\n",
    "    \"P\": \"p\",\n",
    "    \"Q\": \"ʔ\",\n",
    "    \"R\": \"ɹ\",\n",
    "    \"S\": \"s\",\n",
    "    \"SH\": \"ʃ\",\n",
    "    \"T\": \"t\",\n",
    "    \"TH\": \"θ\",\n",
    "    \"V\": \"v\",\n",
    "    \"W\": \"w\",\n",
    "    \"WH\": \"ʍ\",\n",
    "    \"Y\": \"j\",\n",
    "    \"Z\": \"z\",\n",
    "    \"ZH\": \"ʒ\",\n",
    "    \"P\": \"p\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "accent = {0:'',1:\"ˈ\",2:\"ˌ\"}\n",
    "\n",
    "def arpabet_to_ipa_transcription(arpabet_transcription):\n",
    "    ipa_transcription = ''\n",
    "    if isinstance(arpabet_transcription, list):\n",
    "        arpabet_transcription = arpabet_transcription[0]\n",
    "    for phoneme in arpabet_transcription.split():\n",
    "        if phoneme == '#':\n",
    "            break\n",
    "        if phoneme[-1].isdigit():\n",
    "            stress = int(phoneme[-1])\n",
    "            arpabet_phoneme = phoneme[:-1]\n",
    "        else:\n",
    "            stress = 0\n",
    "            arpabet_phoneme = phoneme\n",
    "\n",
    "        ipa_phoneme = arpabet_to_ipa[arpabet_phoneme]\n",
    "        ipa_transcription += accent[stress] + ipa_phoneme\n",
    "\n",
    "    return ipa_transcription.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('static/phoneticDict.json', 'r') as f:\n",
    "    arpabet_dict = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPA_dict = {}\n",
    "\n",
    "for word, transcription in arpabet_dict.items():\n",
    "    if isinstance(transcription, dict):\n",
    "        IPA_dict[word] = {}\n",
    "        for pos, pos_transcription in transcription.items():\n",
    "            ipa_transcription = arpabet_to_ipa_transcription(pos_transcription)\n",
    "            IPA_dict[word][pos] = ipa_transcription\n",
    "    else:\n",
    "        ipa_transcription = arpabet_to_ipa_transcription(transcription)\n",
    "        IPA_dict[word] = ipa_transcription\n",
    "\n",
    "with open('static/IPA_dict.json', 'w') as f:\n",
    "    \n",
    "    json.dump(IPA_dict, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"\\u00a1Hola! espero ayudarte.\\n\\nEn este caso, \\\"work\\\" es sustantivo singular que cumple la funci\\u00f3n de objeto de la preposici\\u00f3n \\\"from\\\". Esta preposici\\u00f3n muestra la relaci\\u00f3n que hay entre la actividad que estaba realizando Mary y su ubicaci\\u00f3n, es decir, que estaba caminando a casa desde el trabajo. \\n\\nEn este sentido, \\\"from work\\\" indica que Mary estaba caminando hacia su hogar despu\\u00e9s de haber finalizado su jornada laboral.\\n\\nAqu\\u00ed te dejo otros ejemplos de uso de \\\"work\\\" como objeto de una preposici\\u00f3n:\\n\\n- She always walks to work.\\n(Ella siempre camina hacia el trabajo.)\\n\\n- He enjoys taking breaks from work to relax.\\n(Le gusta tomar descansos del trabajo para relajarse.)\\n\\n- They had to leave work early because of the storm.\\n(Tuvieron que salir temprano del trabajo debido a la tormenta.) \\n\\nEspero que te haya sido \\u00fatil \\u00a1No dudes en preguntarme cualquier otra cosa!\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1682566113,\n",
      "  \"id\": \"chatcmpl-79mb3803SEOZ6b6qpy70W8Vqzdw2s\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 214,\n",
      "    \"prompt_tokens\": 424,\n",
      "    \"total_tokens\": 638\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = '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'\n",
    "\n",
    "role = \"Present the given information, in a useful manner for an English student. If any challenging linguistic structure is found in the sentence, address it in your explanation. Be brief, a little friendly, add two examples. Your response should be in Spanish.\"\n",
    "userEg = \"\"\"Word: kitten (Singular)\n",
    "Sentence: Mary was walking home from work when she saw an abandoned kitten on the side of the road.\n",
    "Complements:\n",
    "  an \n",
    "  abandoned \n",
    "  on the side of the road\n",
    "Grammar function: Direct object of 'saw'\"\"\"\n",
    "assintantEg = \"\"\"\"kitten\" es un sustantivo singular que funciona como objeto directo del verbo \"saw\", es decir, la acción es realizada sobre el gatito, Mary vio un gatito. Los complementos que lo acompañan son \"an\" (artículo), \"abandoned\" (adjetivo) y \"on the side of the road\" (complemento preposicional) y especifican que se trata de un gatito en particular, y describen su estado y ubicación.\n",
    "\n",
    "Los verbos \"was walking\" indican la acción de caminar de Mary, mientras que el adverbio de tiempo \"when\" señala el momento en que vio al gatito. El verbo \"saw\" denota la acción que realizó Mary, observar al gatito abandonado. \n",
    "\n",
    "Oraciones similares:\n",
    "\n",
    "\tSarah found an injured kitten in the backyard.\n",
    "\t(Sarah encontró un gatito herido en el patio trasero)\n",
    "\n",
    "\tI think I saw a cute kitten in the living room.\n",
    "\t(Me parece que vi un lindo gatito en la sala de estar)\"\"\"\n",
    "\n",
    "request = \"\"\"Word: work(Singular)\n",
    "Sentence: Mary was walking home from work when she saw an abandoned kitten on the side of the road. \n",
    "Function: Object of a preposition of 'from\"\"\"\n",
    "\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": role},\n",
    "        {\"role\": \"user\", \"content\": userEg},\n",
    "        {\"role\": \"assistant\",\n",
    "            \"content\": assintantEg},\n",
    "        {\"role\": \"user\", \"content\": request}\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola! espero ayudarte.\n",
      "\n",
      "En este caso, \"work\" es sustantivo singular que cumple la función de objeto de la preposición \"from\". Esta preposición muestra la relación que hay entre la actividad que estaba realizando Mary y su ubicación, es decir, que estaba caminando a casa desde el trabajo. \n",
      "\n",
      "En este sentido, \"from work\" indica que Mary estaba caminando hacia su hogar después de haber finalizado su jornada laboral.\n",
      "\n",
      "Aquí te dejo otros ejemplos de uso de \"work\" como objeto de una preposición:\n",
      "\n",
      "- She always walks to work.\n",
      "(Ella siempre camina hacia el trabajo.)\n",
      "\n",
      "- He enjoys taking breaks from work to relax.\n",
      "(Le gusta tomar descansos del trabajo para relajarse.)\n",
      "\n",
      "- They had to leave work early because of the storm.\n",
      "(Tuvieron que salir temprano del trabajo debido a la tormenta.) \n",
      "\n",
      "Espero que te haya sido útil ¡No dudes en preguntarme cualquier otra cosa!\n"
     ]
    }
   ],
   "source": [
    "message = response['choices'][0]['message']['content']\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('static/openIA_API_KEY', 'r') as f:\n",
    "    print(f.read())\n",
    "    # openai.api_key ='' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ead1b95f633dc9c51826328e1846203f51a198c6fb5f2884a80417ba131d4e82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
